app-data {
  limit-of-running-out-items = 10
}

http {
  host = "localhost"
  port = 5003
}
mssql {
	password = "etl123"
}
hdfs {
	host = "localhost"
	port = 54310
}
userdatabase{
	name = "database",
	raw_folder_path = "/raw"
}
awss3{
  ac_id = "etl"
	username ="******",
	password ="********",
	accessKey = "********",
	secretAccessKey ="**********"
}
etl{
  host = "localhost"
  port = 5002
}

hive{
	hive_partition = "true",
	hive_partition_mode = "nonstrict",
	spark_warehouse_dir = "hdfs://localhost:54310/user/hive/warehouse",
	metastore = "jdbc:mysql://localhost/hive_metastore?createDatabaseIfNotExist=true",
	ConnectionDriverNameL =  "com.mysql.cj.jdbc.Driver",
	ConnectionUserName = "********",
	ConnectionPassword = "123456"
}
hadoop{
	home = "/work/product/development/softwares/hadoop",
	core_site_path = "/home/hadoop/conf/core-site.xml",
	hdfs_site_path = "/home/hadoop/conf/hdfs-site.xml",
	datanode = "**********"
}
mysql_config { 
	host = "localhost"
	user = "root"
	password = ""
	database = "****"
	insecureAuth = true
	supportBigNumbers = true
}

mysql_ds { 
	host = "localhost"
	user = "root"
	password = ""
	database = "*******"
	insecureAuth = true
	multipleStatements =  true
	dateStrings =  "date"
	supportBigNumbers = true
}
mysql_master{ 
	host = "localhost"
	user = "root"
	password = ""
	database = "*******"
	insecureAuth = true
}

agGraph {
	host = "localhost"
	port = 10035
	user = "*********"
	password = "123456"
	CATALOG_ID = "system"
	repository = "catalyst"
	graph_url = "http://www.etl.com/"
	ag_bin = "path to bin"
	generator_url = "http://www.etl.com/"
}

